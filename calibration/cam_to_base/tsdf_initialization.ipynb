{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import open3d as o3d\n",
    "import cv2\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(base_dir):\n",
    "    rgb_folder = os.path.join(base_dir, 'images')\n",
    "    depth_folder = os.path.join(base_dir, 'depth')\n",
    "    pose_folder = os.path.join(base_dir, 'poses')\n",
    "\n",
    "    print(rgb_folder)\n",
    "\n",
    "    rgb_list, depth_list, pose_list = None, None, None\n",
    "\n",
    "    # Check if RGB folder exists\n",
    "    if os.path.exists(rgb_folder):\n",
    "        # Read RGB images\n",
    "        rgb_files = [f for f in os.listdir(rgb_folder) if f.endswith('.png')]\n",
    "        rgb_files.sort()\n",
    "        print(rgb_files)\n",
    "        rgb_list = []\n",
    "        for f in rgb_files:\n",
    "            img = cv2.imread(os.path.join(rgb_folder, f))\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            rgb_list.append(img)\n",
    "\n",
    "    # Check if depth folder exists\n",
    "    if os.path.exists(depth_folder):\n",
    "        # Read depth images\n",
    "        depth_files = [f for f in os.listdir(depth_folder) if f.endswith('.npy')]\n",
    "        depth_files.sort()\n",
    "        print(depth_files)\n",
    "        depth_list = [np.load(os.path.join(depth_folder, f)) for f in depth_files]\n",
    "\n",
    "    # Check if pose folder exists\n",
    "    if os.path.exists(pose_folder):\n",
    "        # Read poses\n",
    "        pose_files = [f for f in os.listdir(pose_folder) if f.endswith('.npy')]\n",
    "        pose_files.sort()\n",
    "        print(pose_files)\n",
    "        pose_list = [np.load(os.path.join(pose_folder, f)) for f in pose_files]\n",
    "\n",
    "    # Check if camera parameters exist\n",
    "    rgb_params_file = os.path.join(base_dir, 'rgb_intrinsics.npz')\n",
    "    if os.path.exists(rgb_params_file):\n",
    "        # Load the intrinsic parameters\n",
    "        camera_params = np.load(rgb_params_file)\n",
    "        fx = camera_params['fx']\n",
    "        fy = camera_params['fy']\n",
    "        ppx = camera_params['ppx']\n",
    "        ppy = camera_params['ppy']\n",
    "        rgb_coeffs = camera_params['coeffs']\n",
    "        rgb_intrinsics = np.array([[fx, 0, ppx], [0, fy, ppy], [0, 0, 1]])\n",
    "    else:\n",
    "        rgb_intrinsics, rgb_coeffs = None, None\n",
    "\n",
    "    depth_params_file = os.path.join(base_dir, 'depth_intrinsics.npz')\n",
    "    if os.path.exists(depth_params_file):\n",
    "        # Load the intrinsic parameters\n",
    "        camera_params = np.load(depth_params_file)\n",
    "        fx = camera_params['fx']\n",
    "        fy = camera_params['fy']\n",
    "        ppx = camera_params['ppx']\n",
    "        ppy = camera_params['ppy']\n",
    "        depth_coeffs = camera_params['coeffs']\n",
    "        depth_intrinsics = np.array([[fx, 0, ppx], [0, fy, ppy], [0, 0, 1]])\n",
    "        depth_scale = camera_params['depth_scale']\n",
    "    else:\n",
    "        depth_intrinsics, depth_coeffs, depth_scale = None, None, None\n",
    "\n",
    "    return rgb_list, depth_list, pose_list, rgb_intrinsics, rgb_coeffs, depth_intrinsics, depth_coeffs, depth_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../example_data/images\n",
      "['0.png', '1.png', '2.png', '3.png', '4.png', '5.png', '6.png', '7.png', 'left.png', 'right.png']\n",
      "['0.npy', '1.npy', '2.npy', '3.npy', '4.npy', '5.npy', '6.npy', '7.npy', 'left.npy', 'right.npy']\n",
      "['0.npy', '1.npy', '2.npy', '3.npy', '4.npy', '5.npy', '6.npy', '7.npy']\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"../../example_data\"\n",
    "rgb_list, depth_list, arm_pose_list, rgb_intrinsics, rgb_coeffs, depth_intrinsics, depth_coeffs, depth_scale = read_data(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "BaseImage = collections.namedtuple(\n",
    "    \"Image\", [\"id\", \"qvec\", \"tvec\", \"camera_id\", \"name\", \"xys\", \"point3D_ids\"])\n",
    "\n",
    "def qvec2rotmat(qvec):\n",
    "    return np.array([\n",
    "        [1 - 2 * qvec[2]**2 - 2 * qvec[3]**2,\n",
    "         2 * qvec[1] * qvec[2] - 2 * qvec[0] * qvec[3],\n",
    "         2 * qvec[3] * qvec[1] + 2 * qvec[0] * qvec[2]],\n",
    "        [2 * qvec[1] * qvec[2] + 2 * qvec[0] * qvec[3],\n",
    "         1 - 2 * qvec[1]**2 - 2 * qvec[3]**2,\n",
    "         2 * qvec[2] * qvec[3] - 2 * qvec[0] * qvec[1]],\n",
    "        [2 * qvec[3] * qvec[1] - 2 * qvec[0] * qvec[2],\n",
    "         2 * qvec[2] * qvec[3] + 2 * qvec[0] * qvec[1],\n",
    "         1 - 2 * qvec[1]**2 - 2 * qvec[2]**2]])\n",
    "\n",
    "class Image(BaseImage):\n",
    "    def qvec2rotmat(self):\n",
    "        return qvec2rotmat(self.qvec)\n",
    "\n",
    "\n",
    "def read_extrinsics_text(path):\n",
    "    \"\"\"\n",
    "    Taken from https://github.com/colmap/colmap/blob/dev/scripts/python/read_write_model.py\n",
    "    \"\"\"\n",
    "    images = {}\n",
    "    with open(path, \"r\") as fid:\n",
    "        while True:\n",
    "            line = fid.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            line = line.strip()\n",
    "            if len(line) > 0 and line[0] != \"#\":\n",
    "                elems = line.split()\n",
    "                image_id = int(elems[0])\n",
    "                qvec = np.array(tuple(map(float, elems[1:5])))\n",
    "                tvec = np.array(tuple(map(float, elems[5:8])))\n",
    "                camera_id = int(elems[8])\n",
    "                image_name = elems[9]\n",
    "                elems = fid.readline().split()\n",
    "                xys = np.column_stack([tuple(map(float, elems[0::3])),\n",
    "                                       tuple(map(float, elems[1::3]))])\n",
    "                point3D_ids = np.array(tuple(map(int, elems[2::3])))\n",
    "                images[image_id] = Image(\n",
    "                    id=image_id, qvec=qvec, tvec=tvec,\n",
    "                    camera_id=camera_id, name=image_name,\n",
    "                    xys=xys, point3D_ids=point3D_ids)\n",
    "    return images\n",
    "\n",
    "Camera = collections.namedtuple(\n",
    "    \"Camera\", [\"id\", \"model\", \"width\", \"height\", \"params\"])\n",
    "def read_intrinsics_text(path):\n",
    "    \"\"\"\n",
    "    Taken from https://github.com/colmap/colmap/blob/dev/scripts/python/read_write_model.py\n",
    "    \"\"\"\n",
    "    cameras = {}\n",
    "    with open(path, \"r\") as fid:\n",
    "        while True:\n",
    "            line = fid.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            line = line.strip()\n",
    "            if len(line) > 0 and line[0] != \"#\":\n",
    "                elems = line.split()\n",
    "                camera_id = int(elems[0])\n",
    "                model = elems[1]\n",
    "                assert model == \"PINHOLE\", \"While the loader support other types, the rest of the code assumes PINHOLE\"\n",
    "                width = int(elems[2])\n",
    "                height = int(elems[3])\n",
    "                params = np.array(tuple(map(float, elems[4:])))\n",
    "                cameras[camera_id] = Camera(id=camera_id, model=model,\n",
    "                                            width=width, height=height,\n",
    "                                            params=params)\n",
    "    return cameras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the data from colmap format\n",
    "cameras_extrinsic_file = os.path.join(base_dir, \"sparse/0\", \"images.txt\")\n",
    "cam_extrinsics = read_extrinsics_text(cameras_extrinsic_file)\n",
    "pose_list = [None] * len(cam_extrinsics)\n",
    "for key in cam_extrinsics:\n",
    "    extr = cam_extrinsics[key]\n",
    "    R = np.transpose(qvec2rotmat(extr.qvec))\n",
    "    T = np.array(extr.tvec)\n",
    "    pose = np.eye(4)\n",
    "    pose[:3, :3] = R\n",
    "    pose[:3, 3] = -R @ T\n",
    "    pose_list[extr.id-1] = pose\n",
    "\n",
    "\n",
    "cameras_intrinsics_file = os.path.join(base_dir, \"sparse/0\", \"cameras.txt\")\n",
    "cam_intrinsics = read_intrinsics_text(cameras_intrinsics_file)\n",
    "intrinsics_list = [None] * len(cam_intrinsics)\n",
    "\n",
    "if len(cam_intrinsics) == 1:\n",
    "    intr = cam_intrinsics[1]\n",
    "    fx, fy, cx, cy,_ = intr.params\n",
    "    intrinsics_list = [np.array([fx, fy, cx, cy])]*len(cam_extrinsics)\n",
    "\n",
    "for key in cam_intrinsics:\n",
    "    intr = cam_intrinsics[key]\n",
    "    fx, fy, cx, cy,_ = intr.params\n",
    "    intrinsics_list[intr.id-1] = np.array([fx, fy, cx, cy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simply combine all the point clouds to check whether the point clouds are aligned\n",
    "combined_pcd = o3d.geometry.PointCloud()\n",
    "for i in range(0, len(rgb_list),1):\n",
    "    rgb_img = rgb_list[i]\n",
    "    depth_img = depth_list[i]\n",
    "    pose_to_base = pose_list[i]\n",
    "\n",
    "    depth_img = depth_img.astype(np.float32)\n",
    "\n",
    "    rgbd_image = o3d.geometry.RGBDImage.create_from_color_and_depth(\n",
    "        o3d.geometry.Image(rgb_img),\n",
    "        o3d.geometry.Image(depth_img),\n",
    "        depth_scale = 1.0,\n",
    "    )\n",
    "\n",
    "    camera_intrinsic = o3d.camera.PinholeCameraIntrinsic()\n",
    "    camera_intrinsic.set_intrinsics(rgb_img.shape[1], rgb_img.shape[0],\n",
    "                                    intrinsics_list[i][0], intrinsics_list[i][1],\n",
    "                                    intrinsics_list[i][2], intrinsics_list[i][3])\n",
    "\n",
    "    pcd = o3d.geometry.PointCloud.create_from_rgbd_image(\n",
    "        rgbd_image, camera_intrinsic\n",
    "    )\n",
    "    pcd.transform(pose_to_base)\n",
    "\n",
    "    combined_pcd += pcd\n",
    "\n",
    "o3d.visualization.draw_geometries([combined_pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 20.80it/s]\n"
     ]
    }
   ],
   "source": [
    "# Integrate the point clouds into a TSDF volume\n",
    "DEPTH_CUTOFF            = 1\n",
    "VOXEL_SIZE              =0.005\n",
    "\n",
    "volume = o3d.pipelines.integration.ScalableTSDFVolume(\n",
    "    voxel_length=VOXEL_SIZE,\n",
    "    sdf_trunc=3 * VOXEL_SIZE,\n",
    "    color_type=o3d.pipelines.integration.TSDFVolumeColorType.RGB8\n",
    ")\n",
    "\n",
    "for idx in trange(0, len(rgb_list), 1):\n",
    "    pose = pose_list[idx]\n",
    "    rgb = rgb_list[idx]\n",
    "    rgb = np.ascontiguousarray(rgb)\n",
    "    depth = depth_list[idx]\n",
    "    depth[depth > DEPTH_CUTOFF] = 0.0 # remove invalid depth\n",
    "    depth = np.ascontiguousarray(depth.astype(np.float32))\n",
    "\n",
    "    rgb = o3d.geometry.Image(rgb)\n",
    "    depth = o3d.geometry.Image(depth)\n",
    "\n",
    "    rgbd = o3d.geometry.RGBDImage.create_from_color_and_depth(\n",
    "        rgb, depth, depth_scale=1.0, depth_trunc=4.0, convert_rgb_to_intensity=False)\n",
    "\n",
    "    camera_intrinsic = o3d.camera.PinholeCameraIntrinsic()\n",
    "    camera_intrinsic.set_intrinsics(rgb_list[idx].shape[1], rgb_list[idx].shape[0],\n",
    "                                    intrinsics_list[i][0], intrinsics_list[i][1],\n",
    "                                    intrinsics_list[i][2], intrinsics_list[i][3])\n",
    "\n",
    "    intrinsic = camera_intrinsic\n",
    "    extrinsic = np.linalg.inv(pose)\n",
    "    # extrinsic = pose\n",
    "    volume.integrate(rgbd, intrinsic, extrinsic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get mesh and visualize\n",
    "mesh = volume.extract_triangle_mesh()\n",
    "sampled_pcd = mesh.sample_points_uniformly(number_of_points=20000)\n",
    "o3d.visualization.draw_geometries([sampled_pcd])\n",
    "# save sample point cloud\n",
    "save_path = os.path.join(base_dir, \"sparse/0/points3D.ply\")\n",
    "o3d.io.write_point_cloud(save_path, sampled_pcd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
